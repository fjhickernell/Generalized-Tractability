%Introduction to generalized tracability
\documentclass[11pt,compress,xcolor={usenames,dvipsnames},aspectratio=169]{beamer}
%\documentclass[xcolor={usenames,dvipsnames},aspectratio=169]{beamer} %slides and 
%notes
\usepackage[T1]{fontenc}
\usepackage{tgadventor} %Font found at https://tug.org/FontCatalogue/
%\usepackage{newpxtext}
\usepackage[euler-digits,euler-hat-accent]{eulervm}

\usepackage{amsmath,
	amssymb,
	datetime,
	mathtools,
	bbm,
	%mathabx,
	array,
	booktabs,
	xspace,
	multirow,
	calc,
	colortbl,
	siunitx,
 	graphicx}
\usepackage[usenames]{xcolor}
\usepackage[giveninits=false,backend=biber,style=nature, maxcitenames =10, mincitenames=9]{biblatex}
\addbibresource{FJHown23.bib}
\addbibresource{FJH23.bib}
\usepackage{media9}
\usepackage[autolinebreaks]{mcode}
\usepackage[tikz]{mdframed}


\usetheme{FJHSlimNoFoot169}
\setlength{\parskip}{2ex}
\setlength{\arraycolsep}{0.5ex}


\DeclareMathOperator{\COMP}{COMP}
\DeclareMathOperator{\COST}{COST}
\DeclareMathOperator{\ALG}{ALG}
\DeclareMathOperator{\SOL}{SOL}
\DeclareMathOperator{\APP}{APP}
\DeclareMathOperator{\ERR}{ERR}
\DeclareMathOperator{\AVG}{AVG}
\DeclareMathOperator{\INT}{INT}
\DeclareMathOperator{\LIN}{LINEAR}
\DeclareMathOperator{\BAD}{BAD}
%\DeclareMathOperator{\opt}{opt}
\newcommand{\dataN}{\bigl(\hf(\vk_i)\bigr)_{i=1}^n}
\newcommand{\dataNj}{\bigl(\hf(\vk_i)\bigr)_{i=1}^{n_j}}
\newcommand{\dataNjd}{\bigl(\hf(\vk_i)\bigr)_{i=1}^{n_{j^\dagger}}}
\newcommand{\ERRN}{\ERR\bigl(\dataN,n\bigr)}
\newcommand{\otod}{\ensuremath{1\mkern-4mu : \mkern-2mu d}}


%\DeclareMathOperator{\app}{app}

\providecommand{\HickernellFJ}{H.\xspace}


\renewcommand{\OffTitleLength}{-7ex}
\setlength{\FJHThankYouMessageOffset}{-8ex}
\title{Generalized Tractability}
\author[]{Fred J. Hickernell, Peter Kritzer, Onyekachi Osisiogu (?)}
\institute{Department of Applied Mathematics \qquad
	Center for Interdisciplinary Scientific Computation \\
	Illinois Institute of Technology \qquad
	\href{mailto:hickernell@iit.edu}{\url{hickernell@iit.edu}} \qquad
	\href{http://mypages.iit.edu/~hickernell}{\url{mypages.iit.edu/~hickernell}}}

\thanksnote{}
	
%\event{Happy Fred}
\date[]{ revised \today}

\input FJHDef.tex



\begin{document}
	\everymath{\displaystyle}

\frame{\titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{\only<1-3>{Cost of Algorithm, Complexity of the Problem}\only<4->{$d$-Dimensional Problems}}
\vspace{-6ex}
\only<4->{\vspace{-6ex}}
   \begin{gather*}
   \text{\alert{integration \only<1-3>{problem}}\quad} \only<1-3>{\SOL}\only<4->{\SOL_{\alert{d}}}(f) := \only<1-3>{\int_{0}^1}\only<4->{\int_{\alert{[0,1]^d}}} f(x) \, \dif x = \,?,  \quad f \in \only<1-3>{\{f : \norm[2]{f''} \le R \}}\only<4->{\{f : \norm[2]{\partial^{\valpha}f} \le R \; \forall \norm[\infty]{\valpha} \le 2 \}} =: \only<1-3>{\cb}\only<4->{\cb_{\alert{d}}}\\
   \text{\alert{\only<4->{tensor product }trapezoidal rule}\quad} \only<1-3>{\APP}\only<4->{\APP_{\alert{d}}}(f,n) \only<1-3>{:= \frac 1n \biggl( \frac12 f(0) + f(1/n) + \dots + f(1-1/n) + \frac 12 f(1) \biggr)} \\
   \text{\alert{error}\quad}\ERR\only<4->{\alert{_d}}(f,n) = \abs{\only<1-3>{\SOL}\only<4->{\SOL_{\alert{d}}}(f) - \only<1-3>{\APP}\only<4->{\APP_{\alert{d}}}(f,n)} \only<1-3>{\le \frac{R}{8n^2}}\only<4->{ = \Theta(n^{-2/\alert{d}})} \\
   \uncover<2->{\text{\alert{algorithm}\quad} \only<1-3>{\ALG}\only<4->{\ALG_{\alert{d}}}(f,\varepsilon) = \only<1-3>{\APP}\only<4->{\APP_{\alert{d}}}(f,n_\varepsilon), \qquad n_\varepsilon\only<1-3>{ = \sqrt{\frac{R}{8\varepsilon}}} \quad \text{ensures that}\\
   \text{\alert{error criterion}\quad} \abs{\only<1-3>{\SOL}\only<4->{\SOL_{\alert{d}}}(f) - \only<1-3>{\ALG}\only<4->{\ALG_{\alert{d}}}(f,\varepsilon)} \le \varepsilon \quad \forall f \in \cb\only<4->{\alert{_d}} \\
   \text{\alert{information cost} \quad}\COST\only<4->{\alert{_d}}(\only<1-3>{\SOL}\only<4->{\SOL_{\alert{d}}},
   \only<1-3>{\cb}\only<4->{\cb_{\alert{d}}},
   \only<1-3>{\ALG}\only<4->{\ALG_{\alert{d}}},\varepsilon) = n_\varepsilon = \Theta (\varepsilon^{-\only<1-3>{1}\only<4->{\alert{d}}/2}) \text{ as }\varepsilon \to 0}
   \end{gather*}
   
   \vspace{-7ex}
   \uncover<3->{\begin{multline*}
          \text{\alert{computational complexity} \quad}\COMP(\only<1-3>{\SOL}\only<4->{\SOL_{\alert{d}}},
          \only<1-3>{\cb}\only<4->{\cb_{\alert{d}}}
          ,\varepsilon) \\
          = \text{information cost of \alert{best} possible algorithm} = \Theta (\varepsilon^{-1/2}) \text{ as }\varepsilon \to 0
   \end{multline*}}
   \only<5>{What about as \alert{$d \to \infty$?}}
   
\vspace{-7ex}
   \only<3>{\begin{equation*}
          g(\varepsilon) = \Theta (\varepsilon^{-p}) \text{ means }
          \lim_{\varepsilon \to 0} g(\varepsilon) \varepsilon^{q}
          = \begin{cases} 0, & q > p  \\ \infty, & q < p\end{cases}
   \end{equation*}}
   

\end{frame}

\section{Harder and Easier}
\begin{frame}{Linear Problem with Linear Information}
    \vspace{-6ex}
   \begin{gather*}
   \text{\alert{problem}}\quad \SOL_d : \cf_d \to \cg_d,  \qquad \cb_d : = \{f : \norm[\cf_d]{f} \le 1 \} \\
   \SOL_d^*\SOL_d : \cf_d \to \cf_d \text{ has eigenvalues and orthonormal eigenvectors } \\
\lambda_{\max} \ge \lambda_{1,d} \ge \lambda_{2,d} \ge \cdots, \qquad u_{1,d}, u_{2,d}, \ldots, \\
   \text{\alert{approximation}\quad} \APP_d(f,n) = \sum_{i=1}^n \SOL(u_{i,d}) \ip[\cf_d]{f}{u_{i,d}}, \\
   \text{\alert{error}\quad}\ERR_d(f,n) = \norm[\cg]{\SOL_d(f) - \APP_d(f)} \le \sqrt{\lambda_{n+1, d}} \\
   \text{\alert{algorithm}\quad} \ALG_d(f,\varepsilon) = \APP_d(f,n_\varepsilon), \qquad n_\varepsilon = \min \{n \in \natzero : \lambda_{n+1, d} \le \varepsilon^2\} \quad \text{ensures}\\
   \text{\alert{error criterion}\quad} \norm[\cg]{\SOL_d(f) - \ALG_d(f,\varepsilon)} \le \varepsilon \quad \forall f \in \cb_d \\
   \text{\alert{information cost} \quad} \COST_d(\SOL_d,\cb_d,\ALG_d,\varepsilon) = n_\varepsilon = \COMP(\SOL_d,\cb_d,\varepsilon)
   \end{gather*}
   
   \vspace{-3ex}
   The question is $\COMP(\SOL_d,\cb_d,\varepsilon) = \Omega(\varepsilon^{-p} d^q)$? $\Omega(\varepsilon^{-p})$? \\
   \qquad \qquad $\Omega\bigl(\log(1 + \varepsilon^{-p} ) d^q \bigr)$?
   \hfill \hfill as $\varepsilon \to 0$, $d \to \infty$
   

\end{frame}


\end{document}

Let $\cf_d$ and $\cg_d$ Hilbert spaces, and $\SOL_d : \cf_d \to \cg_d$ be a linear solution operator with adjoint $\SOL_d^*$ such that $\SOL_d^*\SOL_d : \cf_d \to \cf_d$ has eigenvalues and orthonormal eigenvectors  
\[
\lambda_{\max} \ge \lambda_{1,d} \ge \lambda_{2,d} \ge \cdots, \qquad u_{1,d}, u_{2,d}, \ldots, 
\]
The goal is to find an approximate solution, $\APP_d:\cb_d \times (0,\infty) \to \cg_d$ satisfying $\norm[\cg_d]{\SOL_d(f) - \APP_d(f,\varepsilon)} \le \varepsilon$, where $\cb_d$ is the unit ball in $\cf_d$ and $\APP_d(f,\varepsilon)$ is allowed to depend on arbitrary linear functionals.  In this case the optimal solution is 
\[
\APP_d(f,\varepsilon) = \sum_{i=1}^n \SOL(u_i) \ip[\cf_d]{f}{u_i},
\]
and the complexity of our linear problem is
\[
\comp(\varepsilon, d) = \min \{n \in \natzero : \lambda_{n+1, d} \le \varepsilon^2\}.
\]